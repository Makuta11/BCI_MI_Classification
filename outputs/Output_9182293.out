Runnin script...
loaded data
created datasets
created dataloaders
initialized model
Training first epoch
1 out of 100
1.1017319680353916
1.098296446549265
2 out of 100
1.0999671406702165
1.0978044635371158
3 out of 100
1.0988821857566133
1.0973958881277788
4 out of 100
1.0979128173731882
1.0970801303261204
5 out of 100
1.0968718654518828
1.0968999222705238
6 out of 100
1.0958917419844811
1.0965755537936561
7 out of 100
1.0948332788747386
1.0964771333493684
8 out of 100
1.0938436274134784
1.0963098802064595
9 out of 100
1.092828401184957
1.09634328766873
10 out of 100
1.0919363635395645
1.0963361225630108
11 out of 100
1.0911245428094076
1.0962570202978035
12 out of 100
1.0903552869044313
1.0962523535678261
13 out of 100
1.089623254373533
1.0963942841479652
14 out of 100
1.089038279625254
1.096418161141245
15 out of 100
1.0884196375488142
1.096415904948586
16 out of 100
1.08787207264419
1.0964707976893375
17 out of 100
1.0874215933161044
1.0964035975305657
18 out of 100
1.0869038400300053
1.0966037900824295
19 out of 100
1.0864540404136027
1.0965192154834145
20 out of 100
1.086032568861585
1.096568095056634
21 out of 100
1.0856399689245662
1.0966250607841894
22 out of 100
1.085245951600031
1.09644708131489
23 out of 100
1.0848982235707274
1.0966326274369893
24 out of 100
1.0845609017468374
1.0966754411396227
25 out of 100
1.0842209939562946
1.0968455603248195
26 out of 100
1.0839294572488978
1.096524257408945
27 out of 100
1.0836177063644479
1.0967344798539813
28 out of 100
1.083357615208407
1.0966756971258866
29 out of 100
1.083054332558168
1.0966065820894744
30 out of 100
1.0827859973688738
1.0963617111507216
31 out of 100
1.0825015552547
1.0965686258516814
32 out of 100
1.0822934459108826
1.0966273056833367
33 out of 100
1.0820528558634837
1.0969208453830919
34 out of 100
1.081813567275301
1.0965198855651053
35 out of 100
1.0816111887266877
1.0967585488369591
36 out of 100
1.0813981349315118
1.0964154958724976
37 out of 100
1.081163820323594
1.0967271855002956
38 out of 100
1.0809902860483993
1.096603344616137
39 out of 100
1.0807579515177175
1.0964640102888408
40 out of 100
1.080580964000947
1.096664043476707
41 out of 100
1.0803757277103738
1.096651382195322
42 out of 100
1.0801746210920702
1.096704898382488
43 out of 100
1.0799934185973001
1.0967059461694015
44 out of 100
1.0797990270710867
1.0964747453990735
45 out of 100
1.0796239195613686
1.0965198579587434
46 out of 100
1.0794571009250955
1.0965142388092843
47 out of 100
1.0792755172886979
1.0963985267438388
48 out of 100
1.079105313217968
1.0963722404680754
49 out of 100
1.0789352064832636
1.096299665852597
50 out of 100
1.0788095423934656
1.0964492258272673
51 out of 100
1.0786330448378116
1.0966292694995279
52 out of 100
1.0784775751446365
1.0965053708929764
53 out of 100
1.078322478390615
1.0964621142337196
54 out of 100
1.0781526002315207
1.0964204988981547
55 out of 100
1.077989624180925
1.0963141478990253
56 out of 100
1.0778915701656167
1.0963658709275095
57 out of 100
1.0776777486188696
1.0961464041157774
58 out of 100
1.0775800166873757
1.096347951889038
59 out of 100
1.077440165598458
1.0961664250022487
60 out of 100
1.0772636374202342
1.0964465191489772
61 out of 100
1.0771165003470324
1.096204830470838
62 out of 100
1.07693357478588
1.0961289644241332
63 out of 100
1.0768292070528782
1.096134594867104
64 out of 100
1.076675003274865
1.096185302734375
65 out of 100
1.0765421581924508
1.096233458268015
66 out of 100
1.0764216135401246
1.0961379151595265
67 out of 100
1.0762432332432599
1.0964455165361102
68 out of 100
1.0760744000793596
1.096142702353628
69 out of 100
1.07595696799252
1.0961731270739907
70 out of 100
1.075758859651898
1.096262828927291
71 out of 100
1.0756351794671575
1.0963144503141704
72 out of 100
1.0754230224758112
1.095960287043923
73 out of 100
1.075290235357547
1.096162321693019
74 out of 100
1.0750787668271895
1.0963704661319131
75 out of 100
1.07492604441599
1.0964613073750547
76 out of 100
1.0747118373529627
1.096082279556676
77 out of 100
1.074511493017914
1.0965441653603
78 out of 100
1.0742880472349465
1.0962938321264166
79 out of 100
1.074076956565227
1.0965295565755744
80 out of 100
1.0737997052866384
1.0962877060237683
81 out of 100
1.0734883453867852
1.0962422232878835
82 out of 100
1.07319127091574
1.0961278840115196
83 out of 100
1.072855496625288
1.0959575138593975
84 out of 100
1.0724834356832942
1.0962691281971177
85 out of 100
1.0720543555163462
1.095857064347518
86 out of 100
1.0716685089496298
1.0953922158793399
87 out of 100
1.0712100327561755
1.095872288001211
88 out of 100
1.0707777919025596
1.0956425127230192
89 out of 100
1.0703524630004113
1.0951818014446058
90 out of 100
1.0699726190042058
1.0953690353192782
91 out of 100
1.0695928783591735
1.095105144852086
92 out of 100
1.069197712688271
1.0953292470229299
93 out of 100
1.0688314049615772
1.0948613769129703
94 out of 100
1.0684487207220235
1.0953117922732705
95 out of 100
1.068129012890912
1.0955267303868343
96 out of 100
1.0676965194010952
1.0952676948748137
97 out of 100
1.0673479076919206
1.0955877479753997
98 out of 100
1.0670019781917608
1.0954163024300023
99 out of 100
1.0665917347330567
1.095279642155296
100 out of 100
1.0662714549160879
1.0955670959071109
trained model
saved model

------------------------------------------------------------
Sender: LSF System <lsfadmin@n-62-11-13>
Subject: Job 9182293: <My_Test_HPC> in cluster <dcc> Done

Job <My_Test_HPC> was submitted from host <gbarlogin2> by user <s164272> in cluster <dcc> at Sun Jan 24 19:58:21 2021
Job was executed on host(s) <n-62-11-13>, in queue <gpuv100>, as user <s164272> in cluster <dcc> at Sun Jan 24 20:09:33 2021
</zhome/08/3/117881> was used as the home directory.
</zhome/08/3/117881/BCI_Project/BCI_MI_Classification> was used as the working directory.
Started at Sun Jan 24 20:09:33 2021
Terminated at Mon Jan 25 02:39:06 2021
Results reported at Mon Jan 25 02:39:06 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -gpu "num=1"
#BSUB -J My_Test
### number of core
#BSUB -n 1 
### specify that all cores should be on the same host
#BSUB -R "span[hosts=1]"
#BSUB -J My_Test_HPC
### specify the memory needed
#BSUB -R "rusage[mem=32GB]"
#BSUB -R "select[gpu32gb]"
### Number of hours needed
#BSUB -W 23:59
### added outputs and errors to files
#BSUB -o outputs/Output_%J.out
#BSUB -e outputs/Error_%J.err

echo "Runnin script..."

python3 main.py 

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22631.88 sec.
    Max Memory :                                 7303 MB
    Average Memory :                             5968.24 MB
    Total Requested Memory :                     32768.00 MB
    Delta Memory :                               25465.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   23373 sec.
    Turnaround time :                            24045 sec.

The output (if any) is above this job summary.



PS:

Read file <outputs/Error_9182293.err> for stderr output of this job.

